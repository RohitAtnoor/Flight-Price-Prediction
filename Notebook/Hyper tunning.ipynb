{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file we will use  the techniques to increase the model performance and accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping the outlier.  \n",
    "We will be using some of the HyperTunning techiniques to traing the model.  \n",
    "1st we will use Ordinal Ecoding.  \n",
    "2nd we will use OneHotEncoder to convert the categorical data.  \n",
    "\n",
    "### Removing the Outliers.  \n",
    "1st we will use Ordinal Ecoding.  \n",
    "2nd we will use OneHotEncoder to convert the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer ## HAndling Missing Values\n",
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "## Model Training\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/flight_dataset.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=os.path.join(\"Data\",\"flight_dataset.csv\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(path)\n",
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_format(Data,Column):\n",
    "    \"\"\"\n",
    "    This function is used to convert the given date format to a correct format.\n",
    "    Complete date column will be splited into saperate columns\n",
    "    Date, Month, Year this are the new columns to be created.\n",
    "    \"\"\" \n",
    "\n",
    "    Data[Column]=pd.to_datetime(Data[Column],infer_datetime_format=True)\n",
    "    Data['Day']=Data[Column].dt.day\n",
    "    Data['Month']=Data[Column].dt.month\n",
    "    Data['Year']=Data[Column].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_399/3225999564.py:8: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Data[Column]=pd.to_datetime(Data[Column],infer_datetime_format=True)\n",
      "/tmp/ipykernel_399/3225999564.py:8: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  Data[Column]=pd.to_datetime(Data[Column],infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "convert_date_format(df,\"Date_of_Journey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_format(Data,deptime,arivaltime):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function convert th 24:00 Hr time format to 2 saperate index hour and min.\n",
    "    New columns with Departure Hour, Arival Hour, Departure Min and Arival Min will be created.\n",
    "    This function can be used when the time is in 00:00 this format. other format will not work(ex 00.00)\n",
    "    \"\"\" \n",
    "    \n",
    "    Data[\"Dep_hour\"]=Data[deptime].str.split(\":\").str[0]\n",
    "    Data[\"Dep_min\"]=Data[deptime].str.split(\":\").str[1]\n",
    "\n",
    "    Data[arivaltime]=Data[arivaltime].str.split(\" \").str[0]\n",
    "    Data[\"Arival_hour\"]=Data[arivaltime].str.split(\":\").str[0]\n",
    "    Data[\"Arival_min\"]=Data[arivaltime].str.split(\":\").str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_time_format(df,\"Dep_Time\",\"Arrival_Time\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Arival_hour</th>\n",
       "      <th>Arival_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>BOM → GOI → PNQ → HYD</td>\n",
       "      <td>16:50</td>\n",
       "      <td>16:55</td>\n",
       "      <td>5m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>17327</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Airline Date_of_Journey  Source Destination                  Route  \\\n",
       "6474  Air India      2019-03-06  Mumbai   Hyderabad  BOM → GOI → PNQ → HYD   \n",
       "\n",
       "     Dep_Time Arrival_Time Duration Total_Stops Additional_Info  Price  Day  \\\n",
       "6474    16:50        16:55       5m     2 stops         No info  17327    6   \n",
       "\n",
       "      Month  Year Dep_hour Dep_min Arival_hour Arival_min  \n",
       "6474      3  2019       16      50          16         55  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Duration\"] == \"5m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(6474,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_travel_time(Data,DurationTime):\n",
    "    \"\"\"\n",
    "    This function is used to conver the travelling time to saperate columns.\n",
    "    Function will create 2 columns travelling hour and travelling min.\n",
    "    \"\"\" \n",
    "\n",
    "    Data[DurationTime]=Data[DurationTime].str.split(\" \")\n",
    "\n",
    "    Data[\"Trveling_hour\"]=Data[DurationTime].str[0].str.split(\"h\").str[0]\n",
    "    Data[\"Trveling_min\"]=Data[DurationTime].str[1].str.split(\"m\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_travel_time(df,\"Duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the categorical value to numerical values.\n",
    "dic={'non-stop':0,'1 stop':1,'2 stops':2,'3 stops':3,'4 stops':4}\n",
    "df[\"Total_Stops\"]=df[\"Total_Stops\"].map(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=[\"Date_of_Journey\",\"Route\",\"Dep_Time\",\"Arrival_Time\",\"Duration\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data before removing duplicates is : (10682, 15)\n",
      "The shape of data after removing duplicates is : (10459, 15)\n"
     ]
    }
   ],
   "source": [
    "# removing the duplicates and Trujet data and nan values.\n",
    "print(f\"The shape of data before removing duplicates is : {df.shape}\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.drop(2878,axis=0,inplace=True)\n",
    "print(f\"The shape of data after removing duplicates is : {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Trveling_min\"]=df[\"Trveling_min\"].fillna(0)\n",
    "df[\"Total_Stops\"]=df[\"Total_Stops\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the object type to Integer type.\n",
    "df[\"Dep_hour\"] = df[\"Dep_hour\"].astype(int)\n",
    "df[\"Dep_min\"] = df[\"Dep_min\"].astype(int)\n",
    "df[\"Arival_hour\"] = df[\"Arival_hour\"].astype(int)\n",
    "df[\"Arival_min\"] = df[\"Arival_min\"].astype(int)\n",
    "df[\"Trveling_hour\"] = df[\"Trveling_hour\"].astype(int)\n",
    "df[\"Trveling_min\"] = df[\"Trveling_min\"].astype(int)\n",
    "df[\"Total_Stops\"] = df[\"Total_Stops\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the columns to independent and dependent columns.\n",
    "X = df.drop(labels=\"Price\",axis=1)\n",
    "Y = df[[\"Price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the columns to categorical and numerical columns.\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "numerical_cols = X.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Pipeline\n",
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scaler',StandardScaler())\n",
    "\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "# Categorigal Pipeline\n",
    "cat_pipeline=Pipeline(\n",
    "    steps=[\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinalencoder',OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('scaler',StandardScaler(with_mean=False))\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "preprocessor=ColumnTransformer([\n",
    "('num_pipeline',num_pipeline,numerical_cols),\n",
    "('cat_pipeline',cat_pipeline,categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training and testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.30,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n",
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
